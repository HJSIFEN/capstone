{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func.search import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_amount': [1661, 2348, 1219, 920, 2499, 2720, 3117, 2096, 2951, 1348, 1971, 2233, 1850, 1529, 2824, 892, 654, 576, 3355, 2148, 1255, 1590, 1668, 823, 1441, 4191, 1365, 3594, 944, 788, 792, 239, 1908, 3096, 2337, 496, 569, 853, 439, 70, 1192, 894, 2461, 1600, 462, 1936, 1711, 691, 1303, 3075, 1685, 2178, 754, 2163, 1456, 2652, 1373, 1685, 820, 3693], 'keyword_mentioned': [5, 13, 7, 6, 20, 3, 5, 4, 10, 3, 12, 6, 1, 6, 14, 20, 12, 7, 7, 2, 6, 1, 5, 4, 2, 17, 4, 20, 1, 12, 2, 1, 2, 1, 15, 2, 12, 2, 1, None, 4, 1, 3, 1, 5, 3, 17, 1, 1, 3, 1, 3, 4, 3, 4, 3, 3, 3, 3, 3], 'commentNum': [2, 1, 0, 2, 12, 5, 6, 2, 0, 0, 0, 4, 2, 0, 20, 0, 0, 0, 3, 0, 2, 0, 1, 2, 0, 6, 1, 43, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 4, 0, 34, 1, 0, 0, 2, 0, 10, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'keyword_100': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'keyword_title_data': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'link_num_data': [1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 3, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 5, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1], 'player_num_data': [0, 5, 0, 0, 1, 1, 5, 4, 0, 0, 0, 11, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'img_num_data': [6, 2, 6, 3, 11, 3, 5, 4, 15, 2, 9, 2, 10, 5, 8, 3, 0, 0, 3, 6, 2, 1, 9, 0, 2, 10, 4, 13, 3, 9, 2, 3, 9, 13, 9, 2, 2, 1, 1, 0, 7, 3, 8, 2, 0, 3, 7, 3, 4, 3, 9, 2, 3, 2, 8, 3, 2, 3, 3, 3], 'post_date': ['2021. 9. 7. 17:57', '2021. 9. 8. 12:00', '2021. 9. 13. 0:19', '2021. 8. 22. 14:44', '2021. 8. 15. 23:21', '2021. 8. 27. 19:58', '2021. 6. 25. 7:10', '2021. 9. 11. 19:32', '2021. 9. 9. 16:02', '2021. 9. 8. 20:00', '2021. 9. 3. 10:19', '2021. 9. 5. 12:46', '2021. 8. 15. 13:26', '2021. 8. 5. 11:14', '2021. 9. 8. 18:17', '2021. 8. 23. 17:47', '2021. 8. 22. 20:18', '2021. 8. 25. 9:00', '2021. 9. 12. 0:11', '2021. 8. 25. 19:23', '2021. 8. 4. 6:53', '2021. 9. 1. 23:41', '2021. 9. 11. 18:02', '2021. 9. 8. 19:07', '2021. 8. 26. 14:02', '2021. 9. 9. 12:20', '2021. 9. 12. 18:43', '2021. 9. 12. 6:29', '1시간 전', '2시간 전', '2021. 8. 26. 23:40', '2021. 9. 8. 19:36', '2021. 8. 26. 19:32', '2021. 9. 9. 3:20', '2021. 8. 31. 13:00', '2021. 9. 9. 12:10', '2021. 6. 25. 10:58', '2021. 8. 10. 8:40', '2021. 9. 10. 12:20', '2021. 8. 17. 11:56', '2021. 9. 10. 6:19', '2021. 9. 12. 18:27', '2021. 8. 26. 19:14', '2021. 9. 6. 10:30', '2021. 7. 29. 8:32', '2021. 9. 12. 10:22', '2021. 9. 11. 6:21', '2021. 8. 26. 18:10', '2021. 8. 28. 23:56', '2021. 9. 12. 13:36', '2021. 7. 29. 6:46', '2021. 9. 4. 17:07', '2021. 9. 1. 18:43', '2021. 9. 5. 11:30', '2021. 8. 21. 23:29', '2021. 9. 13. 15:57', '7시간 전', '2021. 9. 1. 9:00', '2021. 7. 27. 19:52', '2021. 9. 12. 18:16']}\n"
     ]
    }
   ],
   "source": [
    "keyword= '노래'\n",
    "data_dict, text1 = get_data(keyword = keyword, naver_api=False, length = 50)\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tlsrl\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:177: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 194 of the file C:\\Users\\tlsrl\\anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  warnings.warn(self.NO_PARSER_SPECIFIED_WARNING % dict(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2500, 2703, 3116, 2332, 1694, 2662, 3525, 1562, 3314, 1168, 2965, 1696, 4196, 693, 4493, 3709, 1970, 3041, 3436, 2303, 2886, 2853, 1119, 3028, 2471, 1240, 1186, 3149, 1117, 832]\n"
     ]
    }
   ],
   "source": [
    "length= 10\n",
    "keyword = '키워드'\n",
    "\n",
    "data_dict, text1 = get_data(keyword = keyword, length = length)\n",
    "\"\"\"\n",
    "data_dict = 본문 분량, 키워드 언급 횟수, ...\n",
    "text1 = 블로그 내용\n",
    "\n",
    "\"\"\"\n",
    "print(data_dict['text_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-3063d74fa9ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'본문 분량'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_amount'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'키워드 언급 횟수'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keyword_mentioned'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'댓글 개수'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'commentNum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'100자안에 키워드존재'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keyword_100'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'??뭐야이거'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'keyword_title_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'링크 개수'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'link_num_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'동영상 개수'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'player_num_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'이미지 개수'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'img_num_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'작성일자'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'post_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'순위'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rank'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#df.to_csv('data.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'rank'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'본문 분량': data_dict['text_amount'], '키워드 언급 횟수': data_dict['keyword_mentioned'], '댓글 개수': data_dict['commentNum'], '100자안에 키워드존재': data_dict['keyword_100'], '??뭐야이거': data_dict['keyword_title_data'], '링크 개수': data_dict['link_num_data'], '동영상 개수': data_dict['player_num_data'], '이미지 개수': data_dict['img_num_data'], '작성일자': data_dict['post_date'], '순위': data_dict['rank']})\n",
    "\n",
    "#df.to_csv('data.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = df1[['본문 분량', '키워드 언급 횟수', '댓글 개수', '100자안에 키워드존재', '??뭐야이거', '링크 개수', '동영상 개수', '이미지 개수', '작성일자']]\n",
    "y = df1[['rank']]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.75, test_size=0.25)\n",
    " \n",
    "mlr = LinearRegression()\n",
    "mlr.fit(x_train, y_train)\n",
    "\n",
    "y_predict = mlr.predict(x_test)\n",
    "\n",
    "plt.scatter(y_test, y_predict)\n",
    "plt.xlim(0, 60)\n",
    "plt.ylim(0 ,60)\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.title(\"MULTIPLE LINEAR REGRESSION\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
